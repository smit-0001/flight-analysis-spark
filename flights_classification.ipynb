{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flights Delay Prediction using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and session building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "#from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/19 21:07:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv = spark.read.csv('flights.csv', inferSchema=True, header=True)\n",
    "csv.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### converting departure delay into boolean label field to use in classification model\n",
    "specifically a flight that departed late by 30 mins is marked as 1 and filghts that are departed early or late by less than 30 mins are marked as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+---------------+-------------+--------+-----+\n",
      "|DayOfWeek|DayOfMonth|Carrier|OriginAirportID|DestAirportID|ArrDelay|label|\n",
      "+---------+----------+-------+---------------+-------------+--------+-----+\n",
      "|        5|        19|     DL|          11433|        13303|       1|    0|\n",
      "|        5|        19|     DL|          14869|        12478|      -8|    0|\n",
      "|        5|        19|     DL|          14057|        14869|     -15|    0|\n",
      "+---------+----------+-------+---------------+-------------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = csv.select(\"DayOfWeek\", \"DayOfMonth\", \"Carrier\", \"OriginAirportID\", \"DestAirportID\", \"ArrDelay\", ((col(\"DepDelay\") > 15).cast(\"Int\").alias(\"label\")))\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use 70% of the data for training, and reserve 30% for testing. In the testing data, the label column is renamed to trueLabel so I can use it later to compare predicted labels with known actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:==============>                                            (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 1892749 \n",
      " Testing Rows: 809469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "\n",
    "print(\"Training Rows:\", train.count(), \"\\n\", \"Testing Rows:\", test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+---------------+-------------+--------+-----+\n",
      "|DayOfWeek|DayOfMonth|Carrier|OriginAirportID|DestAirportID|ArrDelay|label|\n",
      "+---------+----------+-------+---------------+-------------+--------+-----+\n",
      "|        1|         1|     9E|          10397|        10693|      -6|    0|\n",
      "|        1|         1|     9E|          10397|        12191|     -18|    0|\n",
      "|        1|         1|     9E|          10397|        12191|     -18|    0|\n",
      "+---------+----------+-------+---------------+-------------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+---------------+-------------+--------+---------+\n",
      "|DayOfWeek|DayOfMonth|Carrier|OriginAirportID|DestAirportID|ArrDelay|trueLabel|\n",
      "+---------+----------+-------+---------------+-------------+--------+---------+\n",
      "|        1|         1|     9E|          10423|        13487|     -10|        0|\n",
      "|        1|         1|     9E|          10423|        14869|     -31|        0|\n",
      "|        1|         1|     9E|          10529|        11193|     -10|        0|\n",
      "+---------+----------+-------+---------------+-------------+--------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipepine Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipeline consists of a series of transformer and estimator stages that typically prepare a DataFrame for modeling and then train a predictive model. In this case, you will create a pipeline with seven stages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A StringIndexer estimator that converts string values to indexes for categorical features\n",
    "\n",
    "* A VectorAssembler that combines categorical features into a single vector\n",
    "\n",
    "* A VectorIndexer that creates indexes for a vector of categorical features\n",
    "\n",
    "* A VectorAssembler that creates a vector of continuous numeric features\n",
    "\n",
    "* A MinMaxScaler that normalizes continuous numeric features\n",
    "\n",
    "* A VectorAssembler that creates a vector of categorical and continuous features\n",
    "\n",
    "* A 3 Classifiers that trains a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "strIdx = StringIndexer(inputCol = \"Carrier\", \n",
    "                        outputCol = \"CarrierIdx\")\n",
    "\n",
    "catVect = VectorAssembler(inputCols = [\"CarrierIdx\", \"DayOfMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\",\"ArrDelay\"], \n",
    "                          outputCol=\"catFeatures\")\n",
    "\n",
    "catIdx = VectorIndexer( inputCol = catVect.getOutputCol(), \n",
    "                        outputCol = \"idxCatFeatures\")\n",
    "\n",
    "numVect = VectorAssembler(inputCols = [\"ArrDelay\"], \n",
    "                          outputCol=\"numFeatures\")\n",
    "\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), \n",
    "                      outputCol=\"normFeatures\")\n",
    "\n",
    "featVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], \n",
    "                            outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression , DecisionTreeClassifier , Gradient Boost classifier trains a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\",featuresCol=\"features\",maxIter=10,regParam=0.3)\n",
    "dtc = DecisionTreeClassifier(labelCol=\"label\",featuresCol=\"features\")\n",
    "gbt = GBTClassifier(labelCol='label',featuresCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating 3 different pipeline to train all 3 model on train part of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(stages=[strIdx, catVect, catIdx, numVect, minMax, featVect, lr])\n",
    "pipeline_dtc = Pipeline(stages=[strIdx, catVect, catIdx, numVect, minMax, featVect, dtc])\n",
    "pipeline_gbt = Pipeline(stages=[strIdx, catVect, catIdx, numVect, minMax, featVect, gbt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the pipeline to train the model on train part of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/19 21:09:05 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/09/19 21:09:05 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "plModel_lr = pipeline_lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "plModel_dtc = pipeline_dtc.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "plModel_gbt = pipeline_gbt.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the test data with all of the stages and the trained model in the pipeline to generate label predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lr = plModel_lr.transform(test)\n",
    "predicted_lr = prediction_lr.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "# predicted_lr.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dtc = plModel_dtc.transform(test)\n",
    "predicted_dtc = prediction_dtc.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "# predicted_dtc.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_gbt = plModel_gbt.transform(test)\n",
    "predicted_gbt = prediction_gbt.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "# predicted_gbt.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 276:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|           34313.0|\n",
      "|       FP|             629.0|\n",
      "|       TN|          652598.0|\n",
      "|       FN|          121929.0|\n",
      "|Precision|0.9819987407704196|\n",
      "|   Recall|0.2196144442595461|\n",
      "|       F1|0.3589526320194159|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tp = float(predicted_lr.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp = float(predicted_lr.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn = float(predicted_lr.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn = float(predicted_lr.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "pr = tp / (tp + fp)\n",
    "re = tp / (tp + fn)\n",
    "metrics = spark.createDataFrame([ (\"TP\", tp),\n",
    "                                  (\"FP\", fp),\n",
    "                                  (\"TN\", tn),\n",
    "                                  (\"FN\", fn),\n",
    "                                  (\"Precision\", pr),\n",
    "                                  (\"Recall\", re),\n",
    "                                  (\"F1\", 2*pr*re/(re+pr))],\n",
    "                                  \n",
    "                                  [\"metric\", \"value\"]\n",
    "                                )\n",
    "metrics.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR LR=  0.9580035733283679\n",
      "AUR DTC=  0.6601904434620858\n",
      "AUR GBT=  0.9609189355031346\n"
     ]
    }
   ],
   "source": [
    "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "auroc_lr = binary_evaluator.evaluate(prediction_lr)\n",
    "auroc_dtc = binary_evaluator.evaluate(prediction_dtc)\n",
    "auroc_gbt = binary_evaluator.evaluate(prediction_gbt)\n",
    "\n",
    "print(\"AUR LR= \", auroc_lr)\n",
    "print(\"AUR DTC= \", auroc_dtc)\n",
    "print(\"AUR GBT= \", auroc_gbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acuuracy , Precision , Recall , F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_acc = acc_evaluator.evaluate(prediction_lr)\n",
    "lr_precision = precision_evaluator.evaluate(prediction_lr)\n",
    "lr_rc = recall_evaluator.evaluate(prediction_lr)\n",
    "lr_f1 = f1_evaluator.evaluate(prediction_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dtc_acc = acc_evaluator.evaluate(prediction_dtc)\n",
    "dtc_precision = precision_evaluator.evaluate(prediction_dtc)\n",
    "dtc_rc = recall_evaluator.evaluate(prediction_dtc)\n",
    "dtc_f1 = f1_evaluator.evaluate(prediction_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gbt_acc = acc_evaluator.evaluate(prediction_gbt)\n",
    "gbt_precision = precision_evaluator.evaluate(prediction_gbt)\n",
    "gbt_rc = recall_evaluator.evaluate(prediction_gbt)\n",
    "gbt_f1 = f1_evaluator.evaluate(prediction_gbt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|          Model Name|          Accuracy|         Precision|            Recall|                F1|             AUROC|\n",
      "+--------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "| Logistic Regression|0.8485945724913493|0.8694872277664414|0.8485945724913493|0.8069952722062542|0.9580035733283679|\n",
      "|Decision Tree Cla...|0.9217647618376985|0.9192679801489796|0.9217647618376985|0.9192237385001706|0.6601904434620858|\n",
      "|Gradient Boost Cl...|0.9232472151496846|0.9211126517148436|0.9232472151496846|  0.92158120386093|0.9609189355031346|\n",
      "+--------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = spark.createDataFrame([ (\"Logistic Regression\",lr_acc, lr_precision,lr_rc,lr_f1,auroc_lr) ,\n",
    "                                  (\"Decision Tree Classification\",dtc_acc, dtc_precision,dtc_rc,dtc_f1,auroc_dtc) ,\n",
    "                                  (\"Gradient Boost Classifier\",gbt_acc, gbt_precision, gbt_rc ,gbt_f1,auroc_gbt) \n",
    "                                ],\n",
    "\n",
    "                                [\"Model Name\",\"Accuracy\", \"Precision\",\"Recall\",\"F1\",\"AUROC\"]\n",
    "                              )\n",
    "metrics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
